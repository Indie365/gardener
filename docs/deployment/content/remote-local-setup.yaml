apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: remote-local-setup
  labels: {component: remote-local-setup}
spec:
  selector:
    matchLabels: {component: remote-local-setup}
  template:
    metadata:
      labels: {component: remote-local-setup}
    spec:
      terminationGracePeriodSeconds: 1
      containers:
      - name: dev
        image: docker:26-dind
        command:
        - /bin/sh
        - -c
        - |
          set -ex
          cd
          mkdir -p ~/.cache/apk
          ln -s ~/.cache/apk /etc/apk/cache
          apk add apache2-utils bash bash-completion bat bind-tools conntrack-tools coreutils curl \
                  diffutils dnsmasq docker-bash-completion findutils fzf g++ gawk gcompat git      \
                  git-prompt go grep helm inotify-tools jq k9s less lsof make mandoc mc moreutils  \
                  mount ncurses neovim parallel procps sed strace tar tcpdump tmux tmux-doc tzdata \
                  util-linux vim wget yq
          mkdir -p ~/.cache/wget
          cd ~/.cache/wget
          echo kind            && wget -N "https://kind.sigs.k8s.io/dl/$(curl -sL https://api.github.com/repos/kubernetes-sigs/kind/releases/latest | jq .tag_name -r)/kind-linux-amd64" && cp kind-linux-amd64 /usr/local/bin/kind && chmod +x /usr/local/bin/kind
          echo kns             && wget -N "https://raw.githubusercontent.com/blendle/kns/master/bin/kns" && cp kns /usr/local/bin/kns && chmod +x /usr/local/bin/kns
          echo krew            && wget -N "https://github.com/kubernetes-sigs/krew/releases/download/$(curl -sL https://api.github.com/repos/kubernetes-sigs/krew/releases/latest | jq .tag_name -r)/krew-linux_amd64.tar.gz" && tar -xzf krew-linux_amd64.tar.gz ./krew-linux_amd64 && mv krew-linux_amd64 /usr/local/bin/krew && krew install krew
          echo ktx             && wget -N "https://raw.githubusercontent.com/blendle/kns/master/bin/ktx" && cp ktx /usr/local/bin/ktx && chmod +x /usr/local/bin/ktx
          echo kube-ps1        && wget -N "https://raw.githubusercontent.com/jonmosco/kube-ps1/master/kube-ps1.sh" && cp kube-ps1.sh ~/.kube-ps1.sh
          echo kubectl         && wget -N "https://dl.k8s.io/release/$(curl -sL https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl" && cp kubectl /usr/local/bin/kubectl && chmod +x /usr/local/bin/kubectl
          echo tmux-completion && wget -N "https://raw.githubusercontent.com/imomaliev/tmux-bash-completion/master/completions/tmux" && cp tmux /usr/share/bash-completion/completions/tmux
          echo yaml2json       && wget -N "https://github.com/bronze1man/yaml2json/releases/download/$(curl -sL https://api.github.com/repos/bronze1man/yaml2json/releases/latest | jq .tag_name -r)/yaml2json_linux_amd64" && cp yaml2json_linux_amd64 /usr/local/bin/yaml2json && chmod +x /usr/local/bin/yaml2json
          cd
          bash -c "echo api.{e2e-managedseed.garden,{local,e2e-{managedseed,hib,hib-wl,unpriv,wake-up,wake-up-wl,migrate,migrate-wl,mgr-hib,rotate,rotate-wl,default,default-wl,upd-node,upd-node-wl,upgrade,upgrade-wl,upg-hib,upg-hib-wl}}.local}.{internal,external}.local.gardener.cloud \
                   | sed 's/ /\n/g' | sed 's/^/127.0.0.1 /' | sort >> /etc/hosts"
          echo 'source ~/.bashrc' > ~/.bash_profile
          cat > ~/.bashrc <<"EOF"
            export PATH=/usr/local/go/bin:$PATH
            export KUBECONFIG=~/gardener/example/gardener-local/kind/local/kubeconfig:/tmp/kubeconfig-shoot-local.yaml
            source <(kubectl completion bash)
            alias k=kubectl
            complete -o default -F __start_kubectl k
            source ~/.kube-ps1.sh
            export PS1='[\w $(printf "$(kube_ps1)")]\$ '
            export TERM=xterm-256color
            cd ~/gardener
            echo -e "\e[1;33mTo attach to the \e[1;36mgardener\e[1;33m tmux session, run '\e[1;32mtmux attach -t gardener\e[1;33m'\e[0m"
          EOF
          cat > ~/.tmux.conf <<"EOF"
            set -g mouse on
            set -g mode-keys vi
            set -g default-shell /bin/bash
            set -g pane-border-status top
            set -g pane-border-format " #{pane_index} #{pane_title} - #{pane_current_command} "
          EOF
          [ -d gardener/.git ] || git clone -q https://github.com/gardener/gardener.git
          dockerd-entrypoint.sh &
          until docker ps >/dev/null 2>&1; do sleep 1; done
          tmux new -d -s gardener -n gardener
          tmux select-pane -T top
          tmux send top Enter; sleep 1; tmux send 1; sleep 1; tmux send C; sleep 1; tmux send i; sleep 1; tmux send t; sleep 1; tmux send V; sleep 1; tmux send s; sleep 1; tmux send 5 Enter
          tmux split-window \; select-pane -T kind     ; sleep 1; tmux send "make kind-up # Set up KinD cluster (Garden and Seed)" \; select-layout even-vertical
          tmux split-window \; select-pane -T gardener ; sleep 1; tmux send "make gardener-up # Set up Gardener"\; select-layout even-vertical
          tmux split-window \; select-pane -T shoot    ; sleep 1; tmux send "kubectl apply -f example/provider-local/shoot.yaml # Create a new shoot cluster "\; select-layout even-vertical
          tmux split-window \; select-pane -T config   ; sleep 1; tmux send "./hack/usage/generate-admin-kubeconf.sh > /tmp/kubeconfig-shoot-local.yaml # Get Kubeconfig for Shoot" \; select-layout even-vertical
          tmux split-window \; select-pane -T config   ; sleep 1; tmux send "make test-e2e-local-simple" # Run simple e2e test (create and delete shoot) \; select-layout even-vertical
          touch /tmp/ready
          read
        stdin: true
        startupProbe:
          exec:
            command:
            - cat
            - /tmp/ready
          failureThreshold: 100
          periodSeconds: 5
        resources:
          requests: {cpu: 8, memory: 8G}
          limits:   {cpu: 8, memory: 8G}
        securityContext:
          privileged: true
        volumeMounts:
        # Without bind mounting `/sys/fs/cgroup` the shoot worker node fails currently; all the other components work fine
        # Due to bind mounting `/sys/fs/cgroup` from the host, the docker container in this dind pod (i.e. the KinD cluster) uses a top level cgroup and hence is not constrained by the resource limits of this pod
        # These host cgroups might leak, but it is probably not an issue e.g. due to hibernating the hosting Gardener dev k8s cluster so that the nodes are recreated regularly anyway
        # To avoid conflicts on the top level docker cgroup, one dev pod per node is recommended
        # See
        # https://github.com/kubernetes-sigs/kind/issues/303
        # https://github.com/kubernetes/test-infra/blob/dcf27e157932c3e8680be4ae6cb8a4e2c7acf8cf/config/prow/config.yaml#L978-L988
        # https://github.com/gardener/ci-infra/blob/dff565bced0f386dd1acb0743beb3831dae6c10d/config/prow/config.yaml#L288-L298
        - {name: cgroup,  mountPath: /sys/fs/cgroup}
        - {name: home,    mountPath: /root}
        - {name: home,    mountPath: /var/lib/docker, subPath: .docker}
        - {name: modules, mountPath: /lib/modules, readOnly: true}
      volumes:
      - {name: cgroup,  hostPath: {type: Directory, path: /sys/fs/cgroup}}
      - {name: modules, hostPath: {type: Directory, path: /lib/modules}}
  volumeClaimTemplates:
  - apiVersion: v1
    kind: PersistentVolumeClaim
    metadata: {name: home}
    spec:
      accessModes: [ReadWriteOnce]
      resources: {requests: {storage: 80Gi}}
      volumeMode: Filesystem
